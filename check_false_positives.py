from __future__ import division
from __future__ import print_function
from __future__ import absolute_import

import warnings
warnings.filterwarnings('ignore')
import os
os.environ['TF_CPP_MIN_LOG_LEVEL']='3'

############################################################
                    #CONFIG SETTING
############################################################

class Config:

    def __init__(self):

        # Print the process or not
        self.verbose = True

        # Name of base network
        self.network = 'vgg'

        # Setting for data augmentation
        self.use_horizontal_flips = False
        self.use_vertical_flips = False
        self.rot_90 = False

        # Anchor box scales
    # Note that if im_size is smaller, anchor_box_scales should be scaled
    # Original anchor_box_scales in the paper is [128, 256, 512]
        self.anchor_box_scales = [100, 175, 350]
        #self.anchor_box_scales = [64, 128, 256, 512, 1024]

        # Anchor box ratios
        #self.anchor_box_ratios = [[1, 1], [1./math.sqrt(2), 2./math.sqrt(2)], [2./math.sqrt(2), 1./math.sqrt(2)]]
        self.anchor_box_ratios = [[1, 1], [1, 2], [2, 1]]

        # Size to resize the smallest side of the image
        # Original setting in paper is 600. Set to 300 in here to save training time
        self.im_size = 720

        # image channel-wise mean to subtract
        self.img_channel_mean = [103.939, 116.779, 123.68]
        self.img_scaling_factor = 1.0

        # number of ROIs at once
        self.num_rois = 4

        # stride at the RPN (this depends on the network configuration)
        self.rpn_stride = 16

        self.balanced_classes = False

        # scaling the stdev
        self.std_scaling = 4.0
        self.classifier_regr_std = [8.0, 8.0, 4.0, 4.0]

        # overlaps for RPN
        self.rpn_num_train_examples = 150 
        self.rpn_min_overlap = 0.3
        self.rpn_max_overlap = 0.65

        # overlaps for classifier ROIs
        self.classifier_min_overlap = 0.0
        self.classifier_max_overlap = 0.5

        # placeholder for the class mapping, automatically generated by the parser
        self.class_mapping = None

        self.model_path = None

import argparse

parser = argparse.ArgumentParser(description='Argument')
parser.add_argument('--device', type=str,
                help='device visible for keras (CPU: -1)')
parser.add_argument('--num_rois', type=int,
			    help='num_rois')
parser.add_argument('--graph', type=str,
                help='path to graph folder')
parser.add_argument('--config', type=str,
                help='configuration file')
parser.add_argument('--image_path', type=str,
			    help='images folder')
parser.add_argument('--mode', type=str,
			help='training_mode')
parser.add_argument('--nb_epochs', type=int,
			help='training_mode')   

parser.add_argument('-show','--show', action='store_true')
parser.add_argument('--path_to_np', type=str) 

args = parser.parse_args()

base_path = os.getcwd()
images_path = args.image_path
mode = args.mode
nb_epochs = args.nb_epochs
path_to_np = args.path_to_np
show = args.show

if show:
    from matplotlib import pyplot as plt
    import numpy as np
    from matplotlib import colors as mcolors

    colors = dict(mcolors.BASE_COLORS, **mcolors.CSS4_COLORS)

    FPs=np.load(path_to_np)
    r_epochs = np.arange(0, FPs.shape[1])

    plt.plot(    r_epochs, 
                    FPs[0,:],
                    label='RPN',
                    color=colors['blue'])
    plt.plot(    r_epochs, 
                    FPs[1,:],
                    label='Class',
                    color=colors['gray'])
    plt.legend()
    plt.show()
else : 
    device = args.device
    if device:
        os.environ["CUDA_VISIBLE_DEVICES"]=device

    if args.num_rois:
        num_rois = args.num_rois
    else:
        num_rois = 4

    graph_path = args.graph

    # Load config file
    import pickle
    config_path = args.config
    with open(config_path, 'rb') as f_in:
        C = pickle.load(f_in)

    num_rois = args.num_rois

    import random
    import pprint
    import sys
    import time
    import numpy as np
    from optparse import OptionParser
    import math
    import cv2
    import copy
    from matplotlib import pyplot as plt
    import tensorflow as tf
    import pandas as pd
    import keyboard

    from sklearn.metrics import average_precision_score

    from keras import backend as K
    from keras.optimizers import Adam, SGD, RMSprop
    from keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout
    from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, TimeDistributed
    from keras.engine.topology import get_source_inputs
    from keras.utils import layer_utils
    from keras.utils.data_utils import get_file
    from keras.objectives import categorical_crossentropy

    from keras.models import Model
    from keras.utils import generic_utils
    from keras.engine import Layer, InputSpec
    from keras import initializers, regularizers

    from new_utils import *

    ############################################################
                            #Start testing
    ############################################################


    from tensorflow.python.client import device_lib

    print("List of available devices on tensorflow : ")
    print(device_lib.list_local_devices())

    print("List of available devices on Keras : ")
    print(K.tensorflow_backend._get_available_gpus())
    print("#############")


    # turn off any data augmentation at test time
    C.use_horizontal_flips = False
    C.use_vertical_flips = False
    C.rot_90 = False
    C.num_rois = num_rois

    num_features = 512

    input_shape_img = (None, None, 3)
    input_shape_features = (None, None, num_features)

    img_input = Input(shape=input_shape_img)
    roi_input = Input(shape=(C.num_rois, 4))
    feature_map_input = Input(shape=input_shape_features)

    # define the base network (VGG here, can be Resnet50, Inception, etc)
    shared_layers = nn_base(img_input, trainable=True)

    # define the RPN, built on the base layers
    num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)
    rpn_layers = rpn_layer(shared_layers, num_anchors)

    classifier = classifier_layer(feature_map_input, roi_input, C.num_rois, nb_classes=len(C.class_mapping))

    model_rpn = Model(img_input, rpn_layers)
    model_classifier_only = Model([feature_map_input, roi_input], classifier)

    model_classifier = Model([feature_map_input, roi_input], classifier)

    model_rpn.compile(optimizer='sgd', loss='mse')
    model_classifier.compile(optimizer='sgd', loss='mse')

    # Switch key value for class mapping
    class_mapping = C.class_mapping
    class_mapping = {v: k for k, v in class_mapping.items()}
    print("class_mapping",class_mapping)

    class_to_color = {class_mapping[v]: np.random.randint(0, 255, 3) for v in class_mapping}

    classes = {}
    FPs = np.zeros((2,nb_epochs))

    for id_graph in range(0,nb_epochs):
        
        path = graph_path + '/model_frcnn_vgg_epoch' + mode + str(id_graph) + '.hdf5'
        print('Loading weights from {}'.format(path))
        model_rpn.load_weights(path, by_name=True)
        model_classifier.load_weights(path, by_name=True)

        model_rpn.compile(optimizer='sgd', loss='mse')
        model_classifier.compile(optimizer='sgd', loss='mse')
        img = cv2.imread(images_path)
        X, ratio = format_img(img, C)

        X = np.transpose(X, (0, 2, 3, 1))

        # get output layer Y1, Y2 from the RPN and the feature maps F
        # Y1: y_rpn_cls
        # Y2: y_rpn_regr
        [Y1, Y2, F] = model_rpn.predict(X)

        # Get bboxes by applying NMS 
        # R.shape = (300, 4)
        R,probs = rpn_to_roi(Y1, Y2, C, K.image_dim_ordering(), max_boxes=300, overlap_thresh=0.7)
        FPs[0,id_graph] = np.amax(probs)

        R[:, 2] -= R[:, 0]
        R[:, 3] -= R[:, 1]
        ROIs = np.expand_dims(R, axis=0)
        [P_cls, P_regr] = model_classifier.predict([F, ROIs])
        FPs[1,id_graph] = np.amax(P_cls[0,:,0])

    np.save('../FPs.npy', FPs)
